{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIME GAN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea & Challenge & Explanation\n",
    "- A generative model for time-series data should also learn the temporal dynamics that shapes how one sequence of observations follows another \n",
    "- The model learns a time-series embedding space while optimizing both supervised and adversarial objectives that encourage it to adhere to the dynamics observed while sampling from historical data during training.\n",
    "- A successful generative model for time-series data needs to capture both the cross-sectional distribution of features at each point in time and the longitudinal relationships among these features over time. Expressed in the image context we just discussed, the model needs to learn not only what a realistic image looks like, but also how one image evolves from the next as in a video.\n",
    "\n",
    "#### ! What differentiate it from \"RNN\" Gan \n",
    "TimeGAN explicitly incorporates the autoregressive nature of time series by combining the unsupervised adversarial loss on both real and synthetic sequences familiar from the DCGAN example with a stepwise supervised loss with respect to the original data. The goal is to reward the model for learning the distribution over transitions from one point in time to the next present in the historical data\n",
    "\n",
    "## Ressources\n",
    "- [Kaggle Notebook](https://www.kaggle.com/code/faaizhashmi/generating-synthetic-data-apple-stock-using-gan) \n",
    "- [Medium article ](https://towardsdatascience.com/synthetic-time-series-data-a-gan-approach-869a984f2239)\n",
    "- [Paper](https://papers.nips.cc/paper/2019/file/c9efe5f26cd17ba6216bbe2a7d26d490-Paper.pdf)\n",
    "- [Generative Adversarial Nets for Synthetic Time Series Data](https://github.com/stefan-jansen/machine-learning-for-trading/blob/main/21_gans_for_synthetic_time_series/README.md)\n",
    "\n",
    "## Architecture \n",
    "- TimeGAN architecture introduces the concept of supervised loss —the model is encouraged to capture time conditional distribution within the data by using the original data as a supervision. Also, we can observe the introduction of an embedding network that is responsible to reduce the adversarial learning space dimensionality.\n",
    "\n",
    "- As mentioned above, TimeGAN is a framework to synthesize sequential data compose by 4 networks, that play distinct roles in the process of modelling the data: the expected generator and discriminator, but also, by a recovery and embedder models.\n",
    "\n",
    "### Components (Class) you need to define \n",
    "\n",
    "[See this ](https://github.com/stefan-jansen/machine-learning-for-trading/blob/main/21_gans_for_synthetic_time_series/README.md#the-four-components-of-the-timegan-architecture)\n",
    "1. Supervisor : Take care of the latent space\n",
    "2. Generator (Adversarial Network): \n",
    "3. Discriminator (Adversarial Network): \n",
    "4. Recovery (AE): \n",
    "5. Embedder (AE): \n",
    "\n",
    "The key insight is that the autoencoding components are trained jointly with the adversarial components, such that TimeGAN simultaneously learns to encode features, generate representations, and iterate across time. The embedding network provides the latent space, the adversarial network operates within this space, and the latent dynamics of both real and synthetic data are synchronized through a supervised loss.\n",
    "\n",
    "\n",
    "### Loss function\n",
    "1. The reconstruction loss, which refers to the auto-encoder (embedder & recovery), that in a nutshell compares how well was the reconstruction of the encoded data when compared to the original one.\n",
    "2. The supervised loss that, in a nutshell, is responsible to capture how well the generator approximates the next time step in the latent space.\n",
    "3. The unsupervised loss, this one it’s already familiar to us, a it reflects the relation between the generator and discriminator networks (min-max game). \n",
    "\n",
    "### Training phases\n",
    "1. Training the autoencoder on the provided sequential data for optimal reconstruction\n",
    "2. Training the supervisor using the real sequence data to capture the temporal behavior of the historical information, and finally,\n",
    "3. The combined training of four components while minimizing all the three loss functions mentioned previously.\n",
    "\n",
    "### Concept \n",
    "- Embedding network \n",
    "- Time conditional distribution \n",
    "- adversarial learning space\n",
    "- [Stepwise dependency (and stepwise supervised loss)](https://arxiv.org/abs/2303.15438)\n",
    "- Learn joint distribution : It is expensive to create GANs with different combinations of facial characters P(blond, female, smiling, with glasses), P(brown, male, smiling, no glasses) etc…The curse of dimensionality makes the number of GANs to grow exponentially. Instead, we can learn individual data distribution and combine them to form different distributions. i.e. different attribute combinations.\n",
    "\n",
    "#### Optimization \n",
    "- Professor Forcing involved training an auxiliary discriminator to distinguish between free-running and teacher-forced hidden states, thus encouraging the network’s training and sampling dynamics to converge [2].\n",
    "-  Actor-critic methods [13] have also been proposed, introducing a critic conditioned on target outputs, trained to estimate next-token value functions that guide the actor’s free-running predictions [3]. However, while the motivation for these methods is similar to ours in accounting for stepwise transition dynamics, they are inherently deterministic, and do not accommodate explicitly sampling from a learned distribution—central to our goal of synthetic data generation.\n",
    "\n",
    "### Question \n",
    "- What are the supervised and unsupervised loss?   \n",
    "    - Combinaison de la perte adversaire non supervisée et de la perte supervisée : TimeGAN utilise deux types de pertes lors de l'entraînement. La première est la perte adversaire non supervisée, qui est similaire à celle utilisée dans DCGAN et d'autres GANs. Cette perte encourage le générateur à produire des données qui sont indiscernables de la série temporelle réelle pour le discriminateur. La seconde est une perte supervisée qui compare les séquences générées à la série temporelle réelle. Cette perte encourage le générateur à reproduire les transitions spécifiques d'un point à l'autre dans la série temporelle réelle.\n",
    "- The AR aspect: \n",
    "    - Incorporation de la nature autorégressive des séries temporelles : Les séries temporelles sont souvent autorégressives, ce qui signifie que chaque point de données dépend des points de données précédents. TimeGAN tient compte de cette caractéristique en formant le générateur pour produire non seulement des points de données individuels qui ressemblent à ceux de la série temporelle réelle, mais aussi des séquences de points de données qui maintiennent les mêmes dépendances temporelles.\n",
    "- What part of the architecture is actually learning the temporal dynamics of the data? \n",
    "    - TimeGAN explicitly incorporates the autoregressive nature of time series by combining the unsupervised adversarial loss on both real and synthetic sequences familiar from the DCGAN example with a stepwise supervised loss with respect to the original data. The goal is to reward the model for learning the distribution over transitions from one point in time to the next present in the historical data.\n",
    "    - Answer: 4.1 Embedding and Recovery Functions | The embedding and recovery functions provide mappings between feature and latent space, allowing the adversarial network to learn the underlying temporal dynamics of the data via lower-dimensional representations. \n",
    "- Why does the Generator output in the latent space? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Paper](https://papers.nips.cc/paper/2019/file/c9efe5f26cd17ba6216bbe2a7d26d490-Paper.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Theory](https://papers.nips.cc/paper/2019/file/c9efe5f26cd17ba6216bbe2a7d26d490-Paper.pdf) \n",
    "-  A model is not only tasked with capturing the distributions of features within each time point, it should also capture the potentially complex dynamics of those variables across time\n",
    "- conditional distribution p(xt|x1:t−1) of temporal transitions as well\n",
    "- Autoregressive models explicitly factor the distribution of sequences into a product of conditionals Qt p(xt|x1:t−1). However, while useful in the context of forecasting, this approach is fundamentally deterministic, and is not truly generative in the sense that new sequences can be randomly sampled from them without external conditioning.\n",
    "- Normal GAN on sequential data\n",
    "    - On the other hand, a separate line of work has focused on directly applying the generative adversarial network (GAN) framework to sequential data, primarily by instantiating recurrent networks for the roles of generator and discriminator [4, 5, 6]. While straightforward, the adversarial objective seeks to model p(x1:T ) directly, without leveraging the autoregressive prior. Importantly, simply summing\n",
    "    the standard GAN loss over sequences of vectors may not be sufficient to ensure that the dynamics of the network efficiently captures stepwise dependencies present in the training data\n",
    "\n",
    "- Contribution (new feature): First, in addition to the unsupervised adversarial loss on both real and synthetic sequences, we introduce a stepwise supervised loss using the original data as supervision, thereby explicitly encouraging the model to capture the stepwise conditional distributions in the data.\n",
    "\n",
    "- Second, we introduce an embedding network to provide a reversible mapping between features and latent representations, thereby reducing the high-dimensionality of the adversarial learning space\n",
    "\n",
    "- Supervised loss: Importantly, the supervised loss is minimized by jointly training both the embedding and generator networks, such that the latent space not only serves to promote parameter efficiency—it is specifically conditioned to facilitate the generator in learning temporal relationships.\n",
    "\n",
    "- Our approach is the first to combine the flexibility of the unsupervised GAN framework with the control afforded by supervised training in autoregressive models.\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Litterature review \n",
    "1. Recurrent Conditional GAN (RCGAN) [5] took a similar approach, introducing minor architectural differences such as dropping the dependence on the previous output while conditioning on additional input [14]. A multitude of applied studies have since utilized these frameworks to generate synthetic sequences in such diverse domains as text [15], finance [16], biosignals [17], sensor [18] and smart grid data [19], as well as renewable scenarios [20]. Recent work [6] has proposed conditioning on time stamp information to 2 handle irregularly sampling. However, unlike our proposed technique, these approaches rely only on the binary adversarial feedback for learning, which by itself may not be sufficient to guarantee specifically that the network efficiently captures the temporal dynamics in the training data.\n",
    "2. However, unlike our proposed technique, these approaches rely only on the binary adversarial feedback for learning, which by itself may not be sufficient to guarantee specifically that the network efficiently captures the temporal dynamics in the training data.\n",
    "3.  By contrast, our proposed method generalizes to arbitrary time-series data, incorporates stochasticity at each time step, as well as employing an embedding network to identify a lower-dimensional space for the generative model to learn the stepwise distributions and latent dynamics of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem formulation\n",
    "Consider the general data setting where each instance consists of two elements: static features (that do not change over time, e.g. gender), and temporal features (that occur over time, e.g. vital signs). Let S be a vector space of static features, X of temporal features, and let S ∈ S, X ∈ X be random vectors that can be instantiated with specific values denoted s and x. We consider tuples of the form (S, X1:T ) with some joint distribution p. \n",
    "\n",
    "Our goal is to use training data D to learn a density pˆ(S, X1:T ) that best approximates p(S, X1:T ). This is a high-level objective, and—depending on the lengths, dimensionality, and distribution of the data—may be difficult to optimize in the standard GAN framework. Therefore we additionally make use of the autoregressive decomposition of the joint p(S, X1:T ) = p(S) Qt p(Xt|S, X1:t−1) to focus specifically on the conditionals, yielding the complementary—and simpler—objective of learning a density p(Xt|S, X1:t−1) that best approximates p(Xt|S, X1:t−1) at any time t.\n",
    "\n",
    "#### Two objectives\n",
    "Importantly, this breaks down the sequence-level objective (matching the joint\n",
    "distribution) into a series of stepwise objectives (matching the conditionals). \n",
    "\n",
    "The first is global, min pˆD\u0010 p(S, X1:T )||pˆ(S, X1:T )) (1) \n",
    "\n",
    "where D is some appropriate measure of distance between distributions. \n",
    "\n",
    "The second is local, min pˆD\u0010 p(Xt|S, X1:t−1)||pˆ(Xt|S, X1:t−1) \u0011 (2) \n",
    "\n",
    "for any t. Under an ideal discriminator in the GAN framework, the former takes the form of the Jensen-Shannon divergence. Using the original data for supervision via   maximum-likelihood (ML) training, the latter takes the form of the Kullback-Leibler divergence. Note that minimizing the former relies on the presence of a perfect adversary (which we may not have access to), while minimizing the latter only depends on the presence of ground-truth sequences (which we do have access to). Our target, then, will be a combination of the GAN objective (proportional to Expression 1) and the ML objective (proportional to Expression 2). As we shall see, this naturally yields a training procedure\n",
    "that involves the simple addition of a supervised loss to guide adversarial learning.\n",
    "\n",
    "### Components \n",
    "\n",
    "#### 1. Embedding & Recovery functions\n",
    "- The embedding and recovery functions provide mappings between feature and latent space, allowing the adversarial network to learn the underlying temporal dynamics of the data via lower-dimensional representations. \n",
    "- Note that the embedding and recovery functions can be parameterized by any architecture of choice, with the only stipulation being that they be autoregressive and obey causal ordering (i.e. output(s) at each step can only depend on preceding information). For example, it is just as possible to implement the former with temporal convolutions [31], or the latter via an attention-based decoder [32].\n",
    "\n",
    "#### 2. Sequence Generator and Discriminator\n",
    "- Instead of producing synthetic output directly in feature space, the generator first outputs into the embedding space.\n",
    "- Random vector zS can be sampled from a distribution of choice, and zt follows a stochastic process; here we use the Gaussian distribution and Wiener process\n",
    "- Finally, the discriminator also operates from the embedding space.\n",
    "- Discriminator Architecture: Similarly, there are no restrictions on architecture beyond the generator being autoregressive; here we use a standard recurrent formulation for ease of exposition.\n",
    "\n",
    "#### 3. Jointly Learning to Encode, Generate, and Iterate\n",
    "- First, purely as a reversible mapping between feature and latent spaces, the embedding and recovery functions should enable accurate reconstructions ˜s, x˜1:T of the original data s, x1:T from their latent representations hS , h1:T . Therefore our first objective function is the reconstruction loss \n",
    "- In TimeGAN, the generator is exposed to two types of inputs during training. First, in pure openloop mode, the generator—which is autoregressive—receives synthetic embeddings hˆS , hˆ1:t−1 (i.e. its own previous outputs) in order to generate the next synthetic vector hˆt. Gradients are then computed on the unsupervised loss. This is as one would  xpect—that is, to allow maximizing (for the discriminator) or minimizing (for the generator) the likelihood of providing correct classifications yˆS , yˆ1:T for both the training data hS , h1:T as well as for synthetic output hˆS , hˆ1:T from the generator,\n",
    "- Relying solely on the discriminator’s binary adversarial feedback may not be sufficient incentive for the generator to capture the stepwise conditional distributions in the data. To achieve this more efficiently, we introduce an additional loss to further discipline learning. In an alternating fashion, we also train in closed-loop mode, where the generator receives sequences of embeddings of actual data h1:t−1 (i.e. computed by the embedding network) to generate the next latent vector. Gradients can now be computed on a loss that captures the discrepancy between distributions p(Ht|HS , H1:t−1) and pˆ(Ht|HS , H1:t−1). \n",
    "- Important: While LU pushes the generator to create realistic sequences (evaluated by an imperfect adversary), LS further ensures that it produces similar stepwise transitions (evaluated by ground-truth targets).\n",
    "\n",
    "### Optimization\n",
    "- θe, θr, θg, θd respectively denote the parameters of the embedding, recovery, generator, and discriminator networks\n",
    "- Importantly, LS is included such that the embedding process not only serves to reduce the dimensions of the adversarial learning space—it is actively conditioned to facilitate the generator in learning temporal relationships from the data.\n",
    "- generator and discriminator networks are trained adversarially as follows min θg (ηLS + maxθd LU)\n",
    "- The embedding task serves to regularize adversarial learning—which now occurs in a lower-dimensional latent space.\n",
    "\n",
    "#### Key point \n",
    "1. Therefore we additionally make use of the autoregressive decomposition of the joint p(S, X1:T ) = p(S)Qt p(Xt|S, X1:t−1) to focus specifically on the conditionals, yielding the complementary—and simpler—objective of learning a density pˆ(Xt|S, X1:t−1) that best approximates p(Xt|S, X1:t−1) at any time t\n",
    "\n",
    "2. Look at expression (1) & (2) of two objectives: As we shall see, this naturally yields a training procedure that involves the simple addition of a supervised loss to guide adversarial learning.\n",
    "\n",
    "3. (Doesn't only receives point at one time point) | In TimeGAN, the generator is exposed to two types of inputs during training. First, in pure openloop mode, the generator—which is autoregressive—receives synthetic embeddings hˆS , hˆ1:t−1 (i.e. its own previous outputs) in order to generate the next synthetic vector hˆt.\n",
    "\n",
    "4. Relying solely on the discriminator’s binary adversarial feedback may not be sufficient incentive for the generator to capture the stepwise conditional distributions in the data. To achieve this more efficiently, we introduce an additional loss to further discipline learning. In an alternating fashion, we also train in closed-loop mode, where the generator receives sequences of embeddings of actual data h1:t−1 (i.e. computed by the embedding network) to generate the next latent vector. Gradients can now be computed on a loss that captures the discrepancy between distributions p(Ht|HS , H1:t−1) and pˆ(Ht|HS , H1:t−1). \n",
    "\n",
    "5. Putting it together: Applying maximum likelihood yields the familiar supervised loss,where gX (hS , ht−1, zt) approximates Ezt∼N [ˆp(Ht|HS , H1:t−1, zt)] with one sample zt—as is standard in stochastic gradient descent. In sum, at any step in a training sequence, we assess the difference between the actual next-step latent vector (from the embedding function) and synthetic next-step latent vector (from the generator—conditioned on the actual historical sequence of latents). While LU pushes the generator to create realistic sequences (evaluated by an imperfect adversary), LS further ensures that it produces similar stepwise transitions (evaluated by ground-truth targets).\n",
    "\n",
    "\n",
    "#### Questions\n",
    "1. Understanding the two objectives \n",
    "2. Why does the discriminator work in the embedding space?\n",
    "    - Réduction de la dimensionnalité : Les espaces d'incorporation ont généralement une dimensionnalité beaucoup plus faible que les données d'entrée d'origine. Cela peut rendre le travail du discriminateur plus facile, car il a moins de dimensions à considérer.\n",
    "    - Extraction de caractéristiques : Les espaces d'incorporation sont généralement conçus pour capturer les caractéristiques importantes des données. Par conséquent, en travaillant dans l'espace d'incorporation, le discriminateur peut se concentrer sur ces caractéristiques importantes et ignorer le bruit et les détails inutiles\n",
    "    - Compatibilité avec le générateur : Si le générateur produit des données dans l'espace d'incorporation (comme c'est souvent le cas dans les GANs), alors il est logique de faire fonctionner le discriminateur dans le même espace.\n",
    "    - Amélioration de la performance : Dans de nombreux cas, faire fonctionner le discriminateur dans l'espace d'incorporation peut améliorer la performance du GAN. Par exemple, cela peut aider à stabiliser l'entraînement et à produire des échantillons générés de meilleure qualité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps \n",
    "1. Selecting and preparing real and random time series inputs\n",
    "2. Creating the key TimeGAN model components\n",
    "3. Defining the various loss functions and train steps used during the three training phases\n",
    "4. Running the training loops and logging the results\n",
    "5. Generating synthetic time series and evaluating the results\n",
    "\n",
    "[See notebook](https://github.com/stefan-jansen/machine-learning-for-trading/blob/main/21_gans_for_synthetic_time_series/02_TimeGAN_TF2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. [Data import](https://www.kaggle.com/code/faaizhashmi/generating-synthetic-data-apple-stock-using-gan/notebook#credits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8589</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>27.847500</td>\n",
       "      <td>27.860001</td>\n",
       "      <td>26.837500</td>\n",
       "      <td>27.332500</td>\n",
       "      <td>24.714510</td>\n",
       "      <td>212818400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8590</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>27.072500</td>\n",
       "      <td>27.162500</td>\n",
       "      <td>26.352501</td>\n",
       "      <td>26.562500</td>\n",
       "      <td>24.018263</td>\n",
       "      <td>257142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8591</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>26.635000</td>\n",
       "      <td>26.857500</td>\n",
       "      <td>26.157499</td>\n",
       "      <td>26.565001</td>\n",
       "      <td>24.020523</td>\n",
       "      <td>263188400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8592</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>26.799999</td>\n",
       "      <td>27.049999</td>\n",
       "      <td>26.674999</td>\n",
       "      <td>26.937500</td>\n",
       "      <td>24.357338</td>\n",
       "      <td>160423600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8593</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>27.307501</td>\n",
       "      <td>28.037500</td>\n",
       "      <td>27.174999</td>\n",
       "      <td>27.972500</td>\n",
       "      <td>25.293213</td>\n",
       "      <td>237458000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Open       High        Low      Close  Adj Close  \\\n",
       "8589 2015-01-02  27.847500  27.860001  26.837500  27.332500  24.714510   \n",
       "8590 2015-01-05  27.072500  27.162500  26.352501  26.562500  24.018263   \n",
       "8591 2015-01-06  26.635000  26.857500  26.157499  26.565001  24.020523   \n",
       "8592 2015-01-07  26.799999  27.049999  26.674999  26.937500  24.357338   \n",
       "8593 2015-01-08  27.307501  28.037500  27.174999  27.972500  25.293213   \n",
       "\n",
       "         Volume  \n",
       "8589  212818400  \n",
       "8590  257142000  \n",
       "8591  263188400  \n",
       "8592  160423600  \n",
       "8593  237458000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import this apple stock price dataset and filter from 2015 to 2021\n",
    "# use this path: /Users/philippebeliveau/Desktop/Notebook_Jupyter_R/Synthetic_Data/Dataset/AAPL.csv\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  \n",
    "df = pd.read_csv('/Users/philippebeliveau/Desktop/Notebook_Jupyter_R/Synthetic_Data/Dataset/AAPL.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df[(df['Date'] >= '2015-01-01') & (df['Date'] <= '2021-01-01')]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training phase \n",
    "Phase 1: Autoencoder \n",
    "\n",
    "Phase 2: Supervisor training\n",
    "\n",
    "    def train_supervisor(x):\n",
    "        with tf.GradientTape() as tape:\n",
    "            h = embedder(x)\n",
    "            h_hat_supervised = supervisor(h)\n",
    "            g_loss_s = mse(h[:, 1:, :], h_hat_supervised[:, :-1, :])\n",
    "\n",
    "        var_list = supervisor.trainable_variables\n",
    "        gradients = tape.gradient(g_loss_s, var_list)\n",
    "        supervisor_optimizer.apply_gradients(zip(gradients, var_list))\n",
    "        return g_loss_s\n",
    "\n",
    "*What is the supervisor training doing? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "[See notebook](https://github.com/stefan-jansen/machine-learning-for-trading/blob/main/21_gans_for_synthetic_time_series/03_evaluating_synthetic_data.ipynb)\n",
    "\n",
    "Evaluating the quality of synthetic time-series data\n",
    "The TimeGAN authors assess the quality of the generated data with respect to three practical criteria:\n",
    "\n",
    "Diversity: the distribution of the synthetic samples should roughly match that of the real data\n",
    "Fidelity: the sample series should be indistinguishable from the real data, and\n",
    "Usefulness: the synthetic data should be as useful as their real counterparts for solving a predictive task\n",
    "The authors apply three methods to evaluate whether the synthetic data actually exhibits these characteristics:\n",
    "\n",
    "Visualization: for a qualitative diversity assessment of diversity, we use dimensionality reduction (principal components analysis (PCA) and t-SNE, see Chapter 13) to visually inspect how closely the distribution of the synthetic samples resembles that of the original data\n",
    "Discriminative Score: for a quantitative assessment of fidelity, the test error of a time-series classifier such as a 2-layer LSTM (see Chapter 18) let’s us evaluate whether real and synthetic time series can be differentiated or are, in fact, indistinguishable.\n",
    "Predictive Score: for a quantitative measure of usefulness, we can compare the test errors of a sequence prediction model trained on, alternatively, real or synthetic data to predict the next time step for the real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_flower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
